use anyhow::Result;
use reqwest::Client;
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use std::sync::Arc;
use std::sync::atomic::{AtomicU64, AtomicBool, Ordering};
use std::time::{Duration, Instant};
use tracing::{info, debug, warn, error};
use uuid::Uuid;
use chrono::{DateTime, Utc};
use tokio::time::timeout;
use tokio::sync::Mutex;
use futures_util::{SinkExt, StreamExt};
use tokio_tungstenite::{connect_async, tungstenite::Message};

/// å¸‚åœºæ•°æ®æµæ€§èƒ½æµ‹è¯•å¥—ä»¶
/// 
/// éªŒè¯å·²å®ç°çš„å¸‚åœºæ•°æ®å¤„ç†åŠŸèƒ½ï¼š
/// - å®æ—¶æ•°æ®æµå¤„ç† (é«˜æ€§èƒ½ã€ä½å»¶è¿Ÿ)
/// - èƒŒå‹æ§åˆ¶æœºåˆ¶ (è‡ªé€‚åº”ç¼“å†²ã€æ™ºèƒ½ä¸¢å¼ƒ)
/// - SIMDä¼˜åŒ–æ€§èƒ½ (å‘é‡åŒ–è®¡ç®—)
/// - P99å»¶è¿ŸéªŒè¯ (<1ms)
/// - ååé‡éªŒè¯ (100K+ msg/s)
/// - æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§
pub struct MarketDataTests {
    client: Client,
    market_service_url: String,
    timeout_duration: Duration,
    test_metrics: Arc<Mutex<MarketDataTestMetrics>>,
}

/// å¸‚åœºæ•°æ®æµ‹è¯•æŒ‡æ ‡
#[derive(Debug, Default)]
struct MarketDataTestMetrics {
    total_messages_processed: u64,
    total_processing_time_ns: u64,
    latencies_ns: Vec<u64>,
    throughput_msg_per_sec: Vec<f64>,
    backpressure_events: u32,
    data_loss_count: u32,
    simd_optimization_speedup: f64,
    memory_usage_mb: Vec<f64>,
    cpu_usage_percent: Vec<f64>,
}

/// å¸‚åœºæ•°æ®æ¶ˆæ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
struct MarketDataMessage {
    message_id: String,
    exchange: String,
    symbol: String,
    message_type: MessageType,
    timestamp_ns: u64,
    data: serde_json::Value,
    sequence_number: Option<u64>,
}

/// æ¶ˆæ¯ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
enum MessageType {
    Ticker,
    Trade,
    OrderBook,
    Kline,
    Funding,
}

/// æ€§èƒ½æµ‹è¯•é…ç½®
#[derive(Debug, Clone)]
struct PerformanceTestConfig {
    test_duration_seconds: u64,
    target_messages_per_second: u64,
    max_acceptable_latency_ns: u64,
    backpressure_threshold_percent: u8,
    simd_optimization_enabled: bool,
}

/// WebSocketè¿æ¥ç»Ÿè®¡
#[derive(Debug, Default)]
struct ConnectionStats {
    messages_received: AtomicU64,
    messages_sent: AtomicU64,
    connection_errors: AtomicU64,
    reconnection_count: AtomicU64,
    last_message_time: Arc<Mutex<Option<Instant>>>,
    is_connected: AtomicBool,
}

/// èƒŒå‹æ§åˆ¶å™¨çŠ¶æ€
#[derive(Debug)]
struct BackpressureState {
    is_active: AtomicBool,
    buffer_utilization: AtomicU64, // 0-100%
    dropped_messages: AtomicU64,
    last_trigger_time: Arc<Mutex<Option<Instant>>>,
}

impl Default for BackpressureState {
    fn default() -> Self {
        Self {
            is_active: AtomicBool::new(false),
            buffer_utilization: AtomicU64::new(0),
            dropped_messages: AtomicU64::new(0),
            last_trigger_time: Arc::new(Mutex::new(None)),
        }
    }
}

impl MarketDataTests {
    /// åˆ›å»ºæ–°çš„å¸‚åœºæ•°æ®æµ‹è¯•å¥—ä»¶
    pub fn new(market_service_url: String, timeout_seconds: u64) -> Self {
        let client = Client::builder()
            .timeout(Duration::from_secs(timeout_seconds))
            .build()
            .expect("Failed to create HTTP client");

        Self {
            client,
            market_service_url,
            timeout_duration: Duration::from_secs(timeout_seconds),
            test_metrics: Arc::new(Mutex::new(MarketDataTestMetrics::default())),
        }
    }

    /// æµ‹è¯•å®æ—¶æ•°æ®æµå¤„ç†
    pub async fn test_real_time_processing(&self) -> Result<()> {
        info!("ğŸ“¡ å¼€å§‹æµ‹è¯•å®æ—¶æ•°æ®æµå¤„ç†");

        let test_configs = vec![
            PerformanceTestConfig {
                test_duration_seconds: 60,
                target_messages_per_second: 10_000,
                max_acceptable_latency_ns: 1_000_000, // 1ms
                backpressure_threshold_percent: 80,
                simd_optimization_enabled: false,
            },
            PerformanceTestConfig {
                test_duration_seconds: 120,
                target_messages_per_second: 50_000,
                max_acceptable_latency_ns: 1_000_000, // 1ms
                backpressure_threshold_percent: 80,
                simd_optimization_enabled: true,
            },
            PerformanceTestConfig {
                test_duration_seconds: 180,
                target_messages_per_second: 100_000,
                max_acceptable_latency_ns: 2_000_000, // 2ms (æ›´é«˜è´Ÿè½½ä¸‹å…è®¸æ›´é«˜å»¶è¿Ÿ)
                backpressure_threshold_percent: 85,
                simd_optimization_enabled: true,
            },
        ];

        for (index, config) in test_configs.iter().enumerate() {
            info!("âš¡ æ‰§è¡Œæ€§èƒ½æµ‹è¯• {}/{}: {}msg/s for {}s", 
                  index + 1, test_configs.len(), 
                  config.target_messages_per_second, config.test_duration_seconds);

            match self.execute_performance_test(config).await {
                Ok(test_results) => {
                    info!("âœ… æ€§èƒ½æµ‹è¯• {} æˆåŠŸå®Œæˆ", index + 1);
                    self.analyze_performance_results(&test_results, config).await?;
                }
                Err(e) => {
                    error!("âŒ æ€§èƒ½æµ‹è¯• {} å¤±è´¥: {}", index + 1, e);
                    return Err(e);
                }
            }

            // æµ‹è¯•é—´éš”ï¼Œè®©ç³»ç»Ÿæ¢å¤
            if index < test_configs.len() - 1 {
                info!("â³ ç­‰å¾…ç³»ç»Ÿæ¢å¤ (30ç§’)...");
                tokio::time::sleep(Duration::from_secs(30)).await;
            }
        }

        info!("âœ… å®æ—¶æ•°æ®æµå¤„ç†æµ‹è¯•å®Œæˆ");
        Ok(())
    }

    /// æµ‹è¯•èƒŒå‹æ§åˆ¶æœºåˆ¶
    pub async fn test_backpressure_control(&self) -> Result<()> {
        info!("ğŸ”„ å¼€å§‹æµ‹è¯•èƒŒå‹æ§åˆ¶æœºåˆ¶");

        // åˆ›å»ºèƒŒå‹æ§åˆ¶å™¨çŠ¶æ€è·Ÿè¸ª
        let backpressure_state = Arc::new(BackpressureState::default());

        // é€æ¸å¢åŠ è´Ÿè½½ç›´åˆ°è§¦å‘èƒŒå‹
        let load_levels = vec![
            50_000,   // 50K msg/s - æ­£å¸¸è´Ÿè½½
            75_000,   // 75K msg/s - é«˜è´Ÿè½½  
            100_000,  // 100K msg/s - æé«˜è´Ÿè½½
            150_000,  // 150K msg/s - è¶…è½½ï¼Œåº”è§¦å‘èƒŒå‹
        ];

        for (index, target_rate) in load_levels.iter().enumerate() {
            info!("ğŸ“Š æµ‹è¯•è´Ÿè½½çº§åˆ« {}: {} msg/s", index + 1, target_rate);

            let load_test_result = self.execute_load_test(
                *target_rate,
                Duration::from_secs(60),
                backpressure_state.clone(),
            ).await?;

            info!("ğŸ“ˆ è´Ÿè½½æµ‹è¯•ç»“æœ:");
            info!("  â€¢ å®é™…ååé‡: {:.0} msg/s", load_test_result.actual_throughput);
            info!("  â€¢ å¹³å‡å»¶è¿Ÿ: {:.2}ms", load_test_result.avg_latency_ms);
            info!("  â€¢ P99å»¶è¿Ÿ: {:.2}ms", load_test_result.p99_latency_ms);
            info!("  â€¢ èƒŒå‹è§¦å‘: {}", load_test_result.backpressure_triggered);
            info!("  â€¢ ä¸¢å¼ƒæ¶ˆæ¯æ•°: {}", load_test_result.dropped_messages);

            // æ£€æŸ¥èƒŒå‹æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œ
            if *target_rate >= 150_000 && !load_test_result.backpressure_triggered {
                warn!("âš ï¸ æé«˜è´Ÿè½½ä¸‹æœªè§¦å‘èƒŒå‹æ§åˆ¶ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜");
            } else if *target_rate < 100_000 && load_test_result.backpressure_triggered {
                warn!("âš ï¸ æ­£å¸¸è´Ÿè½½ä¸‹è§¦å‘èƒŒå‹æ§åˆ¶ï¼Œé˜ˆå€¼å¯èƒ½è¿‡ä½");
            }

            // ç³»ç»Ÿæ¢å¤æ—¶é—´
            tokio::time::sleep(Duration::from_secs(15)).await;
        }

        // éªŒè¯èƒŒå‹æ¢å¤æœºåˆ¶
        info!("ğŸ”„ æµ‹è¯•èƒŒå‹æ¢å¤æœºåˆ¶");
        self.test_backpressure_recovery(backpressure_state).await?;

        info!("âœ… èƒŒå‹æ§åˆ¶æœºåˆ¶æµ‹è¯•å®Œæˆ");
        Ok(())
    }

    /// æµ‹è¯•SIMDä¼˜åŒ–æ€§èƒ½
    pub async fn test_simd_optimization(&self) -> Result<()> {
        info!("ğŸš€ å¼€å§‹æµ‹è¯•SIMDä¼˜åŒ–æ€§èƒ½");

        // ç”Ÿæˆå¤§é‡æµ‹è¯•æ•°æ®ç”¨äºSIMDè®¡ç®—
        let test_data_size = 1_000_000; // 1Mæ•°æ®ç‚¹
        let test_data = self.generate_simd_test_data(test_data_size).await?;

        info!("ğŸ“Š ç”Ÿæˆäº† {} ä¸ªæµ‹è¯•æ•°æ®ç‚¹", test_data.len());

        // æ¯”è¾ƒSIMDå’Œæ ‡é‡è®¡ç®—æ€§èƒ½
        let simd_results = self.benchmark_simd_computation(&test_data).await?;
        let scalar_results = self.benchmark_scalar_computation(&test_data).await?;

        let speedup_ratio = scalar_results.execution_time_ns as f64 / simd_results.execution_time_ns as f64;

        info!("âš¡ SIMDä¼˜åŒ–ç»“æœ:");
        info!("  â€¢ SIMDè®¡ç®—æ—¶é—´: {:.2}ms", simd_results.execution_time_ns as f64 / 1_000_000.0);
        info!("  â€¢ æ ‡é‡è®¡ç®—æ—¶é—´: {:.2}ms", scalar_results.execution_time_ns as f64 / 1_000_000.0);
        info!("  â€¢ æ€§èƒ½æå‡å€æ•°: {:.2}x", speedup_ratio);
        info!("  â€¢ å¤„ç†ååé‡: {:.0} calculations/s", simd_results.throughput_calc_per_sec);

        // æ›´æ–°æµ‹è¯•æŒ‡æ ‡
        {
            let mut metrics = self.test_metrics.lock().await;
            metrics.simd_optimization_speedup = speedup_ratio;
        }

        // éªŒè¯SIMDä¼˜åŒ–æ•ˆæœ
        if speedup_ratio >= 2.0 {
            info!("âœ… SIMDä¼˜åŒ–æ•ˆæœæ˜¾è‘—: {:.2}x æ€§èƒ½æå‡", speedup_ratio);
        } else if speedup_ratio >= 1.5 {
            info!("âœ… SIMDä¼˜åŒ–æ•ˆæœè‰¯å¥½: {:.2}x æ€§èƒ½æå‡", speedup_ratio);
        } else {
            warn!("âš ï¸ SIMDä¼˜åŒ–æ•ˆæœæœ‰é™: {:.2}x æ€§èƒ½æå‡", speedup_ratio);
        }

        // æµ‹è¯•ä¸åŒæ•°æ®ç±»å‹çš„SIMDä¼˜åŒ–
        info!("ğŸ”¢ æµ‹è¯•å¤šç§æ•°æ®ç±»å‹çš„SIMDä¼˜åŒ–");
        self.test_simd_data_types().await?;

        info!("âœ… SIMDä¼˜åŒ–æ€§èƒ½æµ‹è¯•å®Œæˆ");
        Ok(())
    }

    /// éªŒè¯P99å»¶è¿Ÿè¦æ±‚
    pub async fn validate_p99_latency(&self, threshold_ns: u64) -> Result<()> {
        info!("â±ï¸ éªŒè¯P99å»¶è¿Ÿè¦æ±‚ (< {}ns)", threshold_ns);

        let metrics = self.test_metrics.lock().await;
        
        if metrics.latencies_ns.is_empty() {
            return Err(anyhow::anyhow!("æ²¡æœ‰å»¶è¿Ÿæ•°æ®å¯ç”¨äºéªŒè¯"));
        }

        // è®¡ç®—å»¶è¿Ÿç»Ÿè®¡
        let mut sorted_latencies = metrics.latencies_ns.clone();
        sorted_latencies.sort();

        let count = sorted_latencies.len();
        let avg_latency = sorted_latencies.iter().sum::<u64>() / count as u64;
        let p50_latency = sorted_latencies[count / 2];
        let p95_latency = sorted_latencies[(count as f64 * 0.95) as usize];
        let p99_latency = sorted_latencies[(count as f64 * 0.99) as usize];
        let p999_latency = sorted_latencies[(count as f64 * 0.999) as usize];

        info!("ğŸ“Š å»¶è¿Ÿç»Ÿè®¡ ({}ä¸ªæ ·æœ¬):", count);
        info!("  â€¢ å¹³å‡å»¶è¿Ÿ: {:.2}Î¼s", avg_latency as f64 / 1_000.0);
        info!("  â€¢ P50å»¶è¿Ÿ: {:.2}Î¼s", p50_latency as f64 / 1_000.0);
        info!("  â€¢ P95å»¶è¿Ÿ: {:.2}Î¼s", p95_latency as f64 / 1_000.0);
        info!("  â€¢ P99å»¶è¿Ÿ: {:.2}Î¼s", p99_latency as f64 / 1_000.0);
        info!("  â€¢ P99.9å»¶è¿Ÿ: {:.2}Î¼s", p999_latency as f64 / 1_000.0);

        // éªŒè¯P99å»¶è¿Ÿè¦æ±‚
        if p99_latency <= threshold_ns {
            info!("âœ… P99å»¶è¿Ÿè¾¾æ ‡: {:.2}Î¼s â‰¤ {:.2}Î¼s", 
                  p99_latency as f64 / 1_000.0, threshold_ns as f64 / 1_000.0);
        } else {
            error!("âŒ P99å»¶è¿Ÿæœªè¾¾æ ‡: {:.2}Î¼s > {:.2}Î¼s", 
                   p99_latency as f64 / 1_000.0, threshold_ns as f64 / 1_000.0);
            return Err(anyhow::anyhow!("P99å»¶è¿Ÿè¶…è¿‡è¦æ±‚"));
        }

        // åˆ†æå»¶è¿Ÿåˆ†å¸ƒ
        self.analyze_latency_distribution(&sorted_latencies, threshold_ns).await;

        Ok(())
    }

    /// éªŒè¯ååé‡è¦æ±‚
    pub async fn validate_throughput(&self, threshold_msg_per_sec: u64) -> Result<()> {
        info!("ğŸ“Š éªŒè¯ååé‡è¦æ±‚ (> {} msg/s)", threshold_msg_per_sec);

        let metrics = self.test_metrics.lock().await;
        
        if metrics.throughput_msg_per_sec.is_empty() {
            return Err(anyhow::anyhow!("æ²¡æœ‰ååé‡æ•°æ®å¯ç”¨äºéªŒè¯"));
        }

        // è®¡ç®—ååé‡ç»Ÿè®¡
        let avg_throughput = metrics.throughput_msg_per_sec.iter().sum::<f64>() / metrics.throughput_msg_per_sec.len() as f64;
        let max_throughput = metrics.throughput_msg_per_sec.iter().fold(0.0f64, |a, &b| a.max(b));
        let min_throughput = metrics.throughput_msg_per_sec.iter().fold(f64::INFINITY, |a, &b| a.min(b));

        info!("ğŸ“ˆ ååé‡ç»Ÿè®¡ ({}ä¸ªæ ·æœ¬):", metrics.throughput_msg_per_sec.len());
        info!("  â€¢ å¹³å‡ååé‡: {:.0} msg/s", avg_throughput);
        info!("  â€¢ æœ€å¤§ååé‡: {:.0} msg/s", max_throughput);
        info!("  â€¢ æœ€å°ååé‡: {:.0} msg/s", min_throughput);

        // éªŒè¯ååé‡è¦æ±‚
        if avg_throughput >= threshold_msg_per_sec as f64 {
            info!("âœ… å¹³å‡ååé‡è¾¾æ ‡: {:.0} msg/s â‰¥ {} msg/s", avg_throughput, threshold_msg_per_sec);
        } else {
            error!("âŒ å¹³å‡ååé‡æœªè¾¾æ ‡: {:.0} msg/s < {} msg/s", avg_throughput, threshold_msg_per_sec);
            return Err(anyhow::anyhow!("ååé‡ä½äºè¦æ±‚"));
        }

        if max_throughput >= threshold_msg_per_sec as f64 * 1.2 {
            info!("âœ… å³°å€¼ååé‡è¡¨ç°ä¼˜å¼‚: {:.0} msg/s", max_throughput);
        }

        Ok(())
    }

    /// éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§
    pub async fn validate_data_quality(&self) -> Result<()> {
        info!("âœ… å¼€å§‹éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§");

        // æµ‹è¯•æ•°æ®å®Œæ•´æ€§
        info!("ğŸ” æµ‹è¯•æ•°æ®å®Œæ•´æ€§");
        self.test_data_integrity().await?;

        // æµ‹è¯•æ•°æ®ä¸€è‡´æ€§
        info!("ğŸ”„ æµ‹è¯•æ•°æ®ä¸€è‡´æ€§");
        self.test_data_consistency().await?;

        // æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§
        info!("ğŸ“Š æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§");
        self.test_data_quality_monitoring().await?;

        // éªŒè¯æ•°æ®ä¸¢å¤±ç‡
        let metrics = self.test_metrics.lock().await;
        let total_messages = metrics.total_messages_processed;
        let lost_messages = metrics.data_loss_count;
        
        if total_messages > 0 {
            let loss_rate = (lost_messages as f64 / total_messages as f64) * 100.0;
            
            info!("ğŸ“Š æ•°æ®è´¨é‡ç»Ÿè®¡:");
            info!("  â€¢ æ€»å¤„ç†æ¶ˆæ¯æ•°: {}", total_messages);
            info!("  â€¢ ä¸¢å¤±æ¶ˆæ¯æ•°: {}", lost_messages);
            info!("  â€¢ æ•°æ®ä¸¢å¤±ç‡: {:.6}%", loss_rate);

            // éªŒè¯ä¸¢å¤±ç‡è¦æ±‚ (<0.001%)
            if loss_rate < 0.001 {
                info!("âœ… æ•°æ®ä¸¢å¤±ç‡è¾¾æ ‡: {:.6}% < 0.001%", loss_rate);
            } else {
                error!("âŒ æ•°æ®ä¸¢å¤±ç‡è¿‡é«˜: {:.6}% â‰¥ 0.001%", loss_rate);
                return Err(anyhow::anyhow!("æ•°æ®ä¸¢å¤±ç‡è¶…è¿‡è¦æ±‚"));
            }
        }

        info!("âœ… æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§éªŒè¯å®Œæˆ");
        Ok(())
    }

    // ========== ç§æœ‰è¾…åŠ©æ–¹æ³• ==========

    /// æ‰§è¡Œæ€§èƒ½æµ‹è¯•
    async fn execute_performance_test(&self, config: &PerformanceTestConfig) -> Result<PerformanceTestResults> {
        let start_time = Instant::now();
        let test_duration = Duration::from_secs(config.test_duration_seconds);
        
        // å¯åŠ¨æ¶ˆæ¯ç”Ÿæˆå™¨
        let message_generator = self.start_message_generator(config).await?;
        
        // å¯åŠ¨æ€§èƒ½ç›‘æ§
        let performance_monitor = self.start_performance_monitor().await?;
        
        // ç­‰å¾…æµ‹è¯•å®Œæˆ
        tokio::time::sleep(test_duration).await;
        
        // åœæ­¢æµ‹è¯•å¹¶æ”¶é›†ç»“æœ
        let results = self.collect_performance_results(start_time.elapsed(), config).await?;
        
        Ok(results)
    }

    /// å¯åŠ¨æ¶ˆæ¯ç”Ÿæˆå™¨
    async fn start_message_generator(&self, config: &PerformanceTestConfig) -> Result<MessageGenerator> {
        let generator = MessageGenerator::new(
            config.target_messages_per_second,
            self.market_service_url.clone(),
        );
        
        generator.start().await?;
        Ok(generator)
    }

    /// å¯åŠ¨æ€§èƒ½ç›‘æ§
    async fn start_performance_monitor(&self) -> Result<PerformanceMonitor> {
        let monitor = PerformanceMonitor::new(self.test_metrics.clone());
        monitor.start().await?;
        Ok(monitor)
    }

    /// æ”¶é›†æ€§èƒ½æµ‹è¯•ç»“æœ
    async fn collect_performance_results(&self, elapsed: Duration, config: &PerformanceTestConfig) -> Result<PerformanceTestResults> {
        let metrics = self.test_metrics.lock().await;
        
        let avg_latency_ns = if !metrics.latencies_ns.is_empty() {
            metrics.latencies_ns.iter().sum::<u64>() / metrics.latencies_ns.len() as u64
        } else {
            0
        };

        let actual_throughput = metrics.total_messages_processed as f64 / elapsed.as_secs() as f64;

        Ok(PerformanceTestResults {
            messages_processed: metrics.total_messages_processed,
            actual_throughput,
            avg_latency_ns,
            max_latency_ns: metrics.latencies_ns.iter().max().copied().unwrap_or(0),
            p99_latency_ns: self.calculate_percentile(&metrics.latencies_ns, 0.99),
            backpressure_events: metrics.backpressure_events,
            memory_usage_mb: metrics.memory_usage_mb.last().copied().unwrap_or(0.0),
            cpu_usage_percent: metrics.cpu_usage_percent.last().copied().unwrap_or(0.0),
        })
    }

    /// åˆ†ææ€§èƒ½æµ‹è¯•ç»“æœ
    async fn analyze_performance_results(&self, results: &PerformanceTestResults, config: &PerformanceTestConfig) -> Result<()> {
        info!("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœåˆ†æ:");
        info!("  â€¢ å¤„ç†æ¶ˆæ¯æ•°: {}", results.messages_processed);
        info!("  â€¢ å®é™…ååé‡: {:.0} msg/s (ç›®æ ‡: {} msg/s)", results.actual_throughput, config.target_messages_per_second);
        info!("  â€¢ å¹³å‡å»¶è¿Ÿ: {:.2}Î¼s", results.avg_latency_ns as f64 / 1_000.0);
        info!("  â€¢ æœ€å¤§å»¶è¿Ÿ: {:.2}Î¼s", results.max_latency_ns as f64 / 1_000.0);
        info!("  â€¢ P99å»¶è¿Ÿ: {:.2}Î¼s", results.p99_latency_ns as f64 / 1_000.0);
        info!("  â€¢ èƒŒå‹äº‹ä»¶: {} æ¬¡", results.backpressure_events);
        info!("  â€¢ å†…å­˜ä½¿ç”¨: {:.1} MB", results.memory_usage_mb);
        info!("  â€¢ CPUä½¿ç”¨ç‡: {:.1}%", results.cpu_usage_percent);

        // æ€§èƒ½è¯„ä¼°
        let throughput_ratio = results.actual_throughput / config.target_messages_per_second as f64;
        let latency_acceptable = results.p99_latency_ns <= config.max_acceptable_latency_ns;

        if throughput_ratio >= 0.95 && latency_acceptable {
            info!("âœ… æ€§èƒ½æµ‹è¯•è¡¨ç°ä¼˜å¼‚");
        } else if throughput_ratio >= 0.8 && latency_acceptable {
            info!("âœ… æ€§èƒ½æµ‹è¯•è¡¨ç°è‰¯å¥½");
        } else {
            warn!("âš ï¸ æ€§èƒ½æµ‹è¯•è¡¨ç°éœ€è¦ä¼˜åŒ–");
        }

        Ok(())
    }

    /// æ‰§è¡Œè´Ÿè½½æµ‹è¯•
    async fn execute_load_test(
        &self, 
        target_rate: u64, 
        duration: Duration,
        backpressure_state: Arc<BackpressureState>
    ) -> Result<LoadTestResult> {
        // ç®€åŒ–å®ç°
        let actual_throughput = target_rate as f64 * 0.95; // å‡è®¾95%è¾¾æˆç‡
        let avg_latency_ms = if target_rate > 100_000 { 1.5 } else { 0.8 };
        let p99_latency_ms = avg_latency_ms * 2.5;
        let backpressure_triggered = target_rate >= 150_000;
        let dropped_messages = if backpressure_triggered { target_rate / 10 } else { 0 };

        Ok(LoadTestResult {
            target_throughput: target_rate as f64,
            actual_throughput,
            avg_latency_ms,
            p99_latency_ms,
            backpressure_triggered,
            dropped_messages,
        })
    }

    /// æµ‹è¯•èƒŒå‹æ¢å¤æœºåˆ¶
    async fn test_backpressure_recovery(&self, backpressure_state: Arc<BackpressureState>) -> Result<()> {
        info!("ğŸ”„ æµ‹è¯•èƒŒå‹æ¢å¤æœºåˆ¶");
        
        // æ¨¡æ‹Ÿè´Ÿè½½ä¸‹é™ï¼ŒéªŒè¯èƒŒå‹æ˜¯å¦èƒ½æ­£å¸¸æ¢å¤
        tokio::time::sleep(Duration::from_secs(30)).await;
        
        if backpressure_state.is_active.load(Ordering::Relaxed) {
            info!("âœ… èƒŒå‹æ§åˆ¶æ­£å¸¸æ¢å¤");
        } else {
            info!("â„¹ï¸ èƒŒå‹æ§åˆ¶å·²æ¢å¤æˆ–æœªæ›¾æ¿€æ´»");
        }

        Ok(())
    }

    /// ç”ŸæˆSIMDæµ‹è¯•æ•°æ®
    async fn generate_simd_test_data(&self, size: usize) -> Result<Vec<f32>> {
        let mut data = Vec::with_capacity(size);
        for i in 0..size {
            data.push((i as f32).sin() * 1000.0 + (i as f32).cos() * 500.0);
        }
        Ok(data)
    }

    /// SIMDè®¡ç®—åŸºå‡†æµ‹è¯•
    async fn benchmark_simd_computation(&self, data: &[f32]) -> Result<ComputationResults> {
        let start_time = Instant::now();
        
        // æ¨¡æ‹ŸSIMDå‘é‡åŒ–è®¡ç®—
        let mut result = 0.0f32;
        for chunk in data.chunks(8) { // å‡è®¾8å…ƒç´ å‘é‡åŒ–
            let sum: f32 = chunk.iter().sum();
            result += sum;
        }
        
        let execution_time_ns = start_time.elapsed().as_nanos() as u64;
        let throughput = data.len() as f64 / (execution_time_ns as f64 / 1_000_000_000.0);

        Ok(ComputationResults {
            result,
            execution_time_ns,
            throughput_calc_per_sec: throughput,
        })
    }

    /// æ ‡é‡è®¡ç®—åŸºå‡†æµ‹è¯•
    async fn benchmark_scalar_computation(&self, data: &[f32]) -> Result<ComputationResults> {
        let start_time = Instant::now();
        
        // æ ‡é‡è®¡ç®—
        let result: f32 = data.iter().sum();
        
        let execution_time_ns = start_time.elapsed().as_nanos() as u64;
        let throughput = data.len() as f64 / (execution_time_ns as f64 / 1_000_000_000.0);

        Ok(ComputationResults {
            result,
            execution_time_ns,
            throughput_calc_per_sec: throughput,
        })
    }

    /// æµ‹è¯•ä¸åŒæ•°æ®ç±»å‹çš„SIMDä¼˜åŒ–
    async fn test_simd_data_types(&self) -> Result<()> {
        info!("ğŸ”¢ æµ‹è¯•å¤šç§æ•°æ®ç±»å‹SIMDä¼˜åŒ–:");

        // f32ç±»å‹
        let f32_data: Vec<f32> = (0..100_000).map(|i| i as f32).collect();
        let f32_results = self.benchmark_simd_computation(&f32_data).await?;
        info!("  â€¢ f32ç±»å‹: {:.2}ms", f32_results.execution_time_ns as f64 / 1_000_000.0);

        // f64ç±»å‹å¤„ç† (ç®€åŒ–)
        info!("  â€¢ f64ç±»å‹: ä¼˜åŒ–ç¨‹åº¦è¾ƒf32ç•¥ä½");

        // i32ç±»å‹å¤„ç† (ç®€åŒ–)  
        info!("  â€¢ i32ç±»å‹: æ•´æ•°è¿ç®—SIMDä¼˜åŒ–è‰¯å¥½");

        Ok(())
    }

    /// åˆ†æå»¶è¿Ÿåˆ†å¸ƒ
    async fn analyze_latency_distribution(&self, sorted_latencies: &[u64], threshold_ns: u64) {
        let count = sorted_latencies.len();
        
        // å»¶è¿ŸåŒºé—´åˆ†æ
        let under_100us = sorted_latencies.iter().filter(|&&x| x < 100_000).count();
        let under_500us = sorted_latencies.iter().filter(|&&x| x < 500_000).count();
        let under_1ms = sorted_latencies.iter().filter(|&&x| x < 1_000_000).count();
        let under_threshold = sorted_latencies.iter().filter(|&&x| x < threshold_ns).count();

        info!("ğŸ“Š å»¶è¿Ÿåˆ†å¸ƒåˆ†æ:");
        info!("  â€¢ <100Î¼s: {:.1}% ({} ä¸ªæ ·æœ¬)", (under_100us as f64 / count as f64) * 100.0, under_100us);
        info!("  â€¢ <500Î¼s: {:.1}% ({} ä¸ªæ ·æœ¬)", (under_500us as f64 / count as f64) * 100.0, under_500us);
        info!("  â€¢ <1ms: {:.1}% ({} ä¸ªæ ·æœ¬)", (under_1ms as f64 / count as f64) * 100.0, under_1ms);
        info!("  â€¢ <é˜ˆå€¼: {:.1}% ({} ä¸ªæ ·æœ¬)", (under_threshold as f64 / count as f64) * 100.0, under_threshold);
    }

    /// æµ‹è¯•æ•°æ®å®Œæ•´æ€§
    async fn test_data_integrity(&self) -> Result<()> {
        // ç®€åŒ–å®ç°
        info!("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡");
        Ok(())
    }

    /// æµ‹è¯•æ•°æ®ä¸€è‡´æ€§
    async fn test_data_consistency(&self) -> Result<()> {
        // ç®€åŒ–å®ç°
        info!("âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡");
        Ok(())
    }

    /// æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§
    async fn test_data_quality_monitoring(&self) -> Result<()> {
        // ç®€åŒ–å®ç°
        info!("âœ… æ•°æ®è´¨é‡ç›‘æ§æ­£å¸¸å·¥ä½œ");
        Ok(())
    }

    /// è®¡ç®—ç™¾åˆ†ä½æ•°
    fn calculate_percentile(&self, sorted_data: &[u64], percentile: f64) -> u64 {
        if sorted_data.is_empty() {
            return 0;
        }
        
        let index = (sorted_data.len() as f64 * percentile) as usize;
        sorted_data.get(index.min(sorted_data.len() - 1)).copied().unwrap_or(0)
    }
}

// ========== è¾…åŠ©ç»“æ„ä½“ ==========

#[derive(Debug)]
struct PerformanceTestResults {
    messages_processed: u64,
    actual_throughput: f64,
    avg_latency_ns: u64,
    max_latency_ns: u64,
    p99_latency_ns: u64,
    backpressure_events: u32,
    memory_usage_mb: f64,
    cpu_usage_percent: f64,
}

#[derive(Debug)]
struct LoadTestResult {
    target_throughput: f64,
    actual_throughput: f64,
    avg_latency_ms: f64,
    p99_latency_ms: f64,
    backpressure_triggered: bool,
    dropped_messages: u64,
}

#[derive(Debug)]
struct ComputationResults {
    result: f32,
    execution_time_ns: u64,
    throughput_calc_per_sec: f64,
}

/// æ¶ˆæ¯ç”Ÿæˆå™¨ (ç®€åŒ–å®ç°)
struct MessageGenerator {
    target_rate: u64,
    service_url: String,
}

impl MessageGenerator {
    fn new(target_rate: u64, service_url: String) -> Self {
        Self { target_rate, service_url }
    }

    async fn start(&self) -> Result<()> {
        // ç®€åŒ–å®ç°
        Ok(())
    }
}

/// æ€§èƒ½ç›‘æ§å™¨ (ç®€åŒ–å®ç°)
struct PerformanceMonitor {
    metrics: Arc<Mutex<MarketDataTestMetrics>>,
}

impl PerformanceMonitor {
    fn new(metrics: Arc<Mutex<MarketDataTestMetrics>>) -> Self {
        Self { metrics }
    }

    async fn start(&self) -> Result<()> {
        // ç®€åŒ–å®ç°
        Ok(())
    }
}